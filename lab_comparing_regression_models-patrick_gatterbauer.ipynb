{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab1dca4",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "1) In this final lab, we will model our data. Import sklearn train_test_split and separate the data.\n",
    "2) Try a simple linear regression with all the data to see whether we are getting good results.\n",
    "3) Great! Now define a function that takes a list of models and train (and tests) them so we can try a lot of them without repeating code.\n",
    "4) Use the function to check LinearRegressor and KNeighborsRegressor.\n",
    "5) You can check also the MLPRegressor for this task!\n",
    "6) Check and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac70791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c12b2",
   "metadata": {},
   "source": [
    "## Data collection and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('files_for_lab/we_fn_use_c_marketing_customer_value_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd72c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c99e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8959b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba813f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change capitalization to lowercase and replace spaces with underscores:\n",
    "customer_df.columns = customer_df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddfbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['effective_to_date'] = pd.to_datetime(customer_df['effective_to_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "round((customer_df.isna().sum()/len(customer_df)*100),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.customer.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25452c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals = customer_df.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b566dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41648f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numericals:\n",
    "    print(numericals[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numericals:\n",
    "    numericals[column].hist()\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dtypes(numericals):\n",
    "    data = numericals.dtypes\n",
    "    x=0\n",
    "    for i in range (len(numericals.columns)):\n",
    "        print(data[x],\" \", numericals.iloc[0][numericals.columns[i]],\" \",numericals.columns[i])\n",
    "        x+=1\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dtypes(numericals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3eed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete: number_of_policies, number_of_open_complaints, months_since_policy_inception, months_since_last_claim\n",
    "# Continuous: monthly_premium_auto, total_claim_amount,income,customer_lifetime_value\n",
    "# Why monthly_premium_auto is in continous: it's calculated based \n",
    "# on a lot of different criteria (type of cars, policies taken, age of the main driver, how many accidents you had and when etc.)\n",
    "# so with all these combinations of inputs we can get any number of monthly_premium_auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals['income'] = numericals['income'].astype(float)\n",
    "numericals['monthly_premium_auto'] = numericals['income'].astype(float)\n",
    "check_dtypes(numericals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ec25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes == 'int64':\n",
    "            df1 = df.select_dtypes(include='int64')\n",
    "            discrete = df1.to_dict()\n",
    "        else:\n",
    "            df2 = df.select_dtypes(include='float64')\n",
    "            continuous = df2.to_dict()\n",
    "    return continuous, discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous, discrete = to_dict(numericals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e38647",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2dbb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = customer_df.select_dtypes(np.object)\n",
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a695041",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cat:\n",
    "    print(cat[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ae1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cat:\n",
    "    print(len(cat[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60541bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dtypes(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81431e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer => continuous but would be better to set it as the index\n",
    "# all the other variables are discrete\n",
    "# text in cat variable is already clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if we're meant to add the cat variables to the discrete variable\n",
    "cat_dict = cat.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8113e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_discrete = discrete | cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_discrete.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_df = pd.DataFrame.from_dict(discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4223b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_df.reset_index(drop=True, inplace=True)\n",
    "cat.reset_index(drop=True, inplace=True)\n",
    "discrete_df = pd.concat([discrete_df, cat], axis=1)\n",
    "discrete_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a64e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_df = pd.DataFrame.from_dict(continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db72ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. What should we do with the customer_id column? => should be set as the index\n",
    "customer_df = customer_df.set_index('customer')\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f881c03a",
   "metadata": {},
   "source": [
    "## Lab | Cleaning categorical data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e03ce",
   "metadata": {},
   "source": [
    "3. Plot a correlation matrix, what can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c58802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr for continous_df\n",
    "continuous_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(continuous_df.corr()) \n",
    "mask[np.triu_indices_from(mask)] = True \n",
    "#use mask to see just 50% of the matrix -> easay to \"read\"\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.heatmap(continuous_df.corr(), mask=mask, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income and monthly_premium_auto have correlation of 1\n",
    "# otherwise there are no special findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr for descrete_dfabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(discrete_df.corr()) \n",
    "mask[np.triu_indices_from(mask)] = True \n",
    "#use mask to see just 50% of the matrix -> easay to \"read\"\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.heatmap(discrete_df.corr(), mask=mask, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbffb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just low correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121050f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot every discrete variables\n",
    "for column in discrete_df:\n",
    "    discrete_df[column].hist()\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot every conitnous variables\n",
    "#first include defien new variable with \"total_claim_amount\" to compare\n",
    "cols_to_include = continuous_df.loc[:, continuous_df.columns != 'total_claim_amount']\n",
    "for column in cols_to_include:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.scatterplot(continuous_df[column],continuous_df['total_claim_amount'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations: there seems to be not a lot of correlation \n",
    "# between the monthly_premium_auto, the income and the target\n",
    "# But there is a correlation between the \n",
    "# customer_lifetime_value and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot for continuous variables\n",
    "for col in continuous_df:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.boxplot(x=continuous_df[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_claim_amount and customer_lifetime_value have the most outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff00841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, threshold=1.5):\n",
    "    numerical = df.select_dtypes(np.number)\n",
    "    columns = numerical.columns\n",
    "    for column in columns:\n",
    "        if len(df[column].unique()) < 10:\n",
    "            continue\n",
    "        else:\n",
    "            upper = np.percentile(df[column], 75)\n",
    "            lower = np.percentile(df[column], 25)\n",
    "            iqr = upper - lower\n",
    "            upper_limit = upper + threshold * iqr\n",
    "            lower_limit = lower - threshold * iqr\n",
    "            df = df[(df[column]>lower_limit) & (df[column]<upper_limit)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a949614",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = remove_outliers(continuous_df, threshold=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2628ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in continuous:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.boxplot(x=continuous[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2702798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking NaNs per column\n",
    "def check_nan(df):\n",
    "    nulls = pd.DataFrame(df.isna().sum()/len(df))\n",
    "    nulls= nulls.reset_index()\n",
    "    nulls.columns = ['column_name', 'Percentage Null Values']\n",
    "    nulls.sort_values(by='Percentage Null Values', ascending = False)\n",
    "    return nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b043ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = check_nan(continuous)\n",
    "cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = check_nan(discrete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. for the categorical data, check if there is some kind of text in a variable so we would need to clean it. \n",
    "# Hint: Use the same method you used in step 7. \n",
    "# Depending on the implementation, decide what to do with the variables you get.\n",
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dde541",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat:\n",
    "    x = cat[col].unique()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 to 12 is already done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904472a0",
   "metadata": {},
   "source": [
    "# lab-feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Open the categoricals variable we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Plot all the categorical variables with the proper plot. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use histograms to see distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ace99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55591e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aba1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_df['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d16789",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75802a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use boxplot to see outliers\n",
    "# also here: compare\n",
    "for col in cat:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.boxplot(x=cat[col], y=continuous_df['total_claim_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7186150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use also barplot to see relationship between a numeric and a categoric variable\n",
    "# for numeric choose target \"total_claim_amount\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(x=cat[col], y=continuous_df['total_claim_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b44ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. There might be some columns that seem to be redundant, check their values to be sure. What should we do with them?\n",
    "# gender and sales_channel\n",
    "# also policy_type and vehicle_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cat.drop(['gender','policy_type','sales_channel', 'vehicle_size'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adce5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Plot time variable. Can you extract something from it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51afaf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try barplot -> makes no sense\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=customer_df['effective_to_date'], y=customer_df['total_claim_amount'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sns lineplot\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "sns.lineplot(customer_df['effective_to_date'], customer_df['total_claim_amount'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a88ccf",
   "metadata": {},
   "source": [
    "# Lab | Data cleaning and wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641acb53",
   "metadata": {},
   "source": [
    "1. We will start with removing outliers. So far, we have discussed different methods to remove outliers.\n",
    "Use the one you feel more comfortable with, define a function for that. Use the function to remove the outliers and apply it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, threshold=1.5):\n",
    "    numerical = df.select_dtypes(np.number)\n",
    "    columns = numerical.columns\n",
    "    for column in columns:\n",
    "        if len(df[column].unique()) < 10:\n",
    "            continue\n",
    "        else:\n",
    "            upper = np.percentile(df[column], 75)\n",
    "            lower = np.percentile(df[column], 25)\n",
    "            iqr = upper - lower\n",
    "            upper_limit = upper + threshold * iqr\n",
    "            lower_limit = lower - threshold * iqr\n",
    "            df = df[(df[column]>lower_limit) & (df[column]<upper_limit)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd1472",
   "metadata": {},
   "source": [
    "2. Create a copy of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe155046",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = customer_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555fe49",
   "metadata": {},
   "source": [
    "3. Normalize the continuous variables. You can use any one method you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fcabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standardscale\n",
    "transformer = StandardScaler().fit(continuous)\n",
    "x_standardized = transformer.transform(continuous)\n",
    "X = pd.DataFrame(x_standardized)\n",
    "X.columns = continuous.columns\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0017a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the numerical dataframes:\n",
    "len(discrete_df)-len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a left join\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "discrete_df.reset_index(drop=True, inplace=True)\n",
    "numerical_df = pd.merge(X, discrete_df, how='left', left_index=True, right_index=True)\n",
    "numerical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693303f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Encode the categorical variables\n",
    "cat_encoded = pd.get_dummies(cat, columns=cat.columns, drop_first=True)\n",
    "cat_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc73f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48391287",
   "metadata": {},
   "source": [
    "5. The time variable can be useful. Try to transform its data into a useful one.\n",
    "Hint: Day week and month as integers might be useful. \\ => Has already been done in order to plot the datetime data. \\ I will apply the same method on data_copy and drop the effective_to_date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['month']= data_copy['effective_to_date'].dt.month\n",
    "data_copy['day']= data_copy['effective_to_date'].dt.day\n",
    "data_copy = data_copy.drop(['effective_to_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a95142",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89001ed4",
   "metadata": {},
   "source": [
    "6. Since the model will only accept numerical data:\n",
    "Check and make sure that every column is numerical, if some are not, change it using encoding: \\ \\ One hot to state \\ Ordinal to coverage \\ Ordinal to employmentstatus \\ Ordinal to location code \\ One hot to marital status \\ One hot to policy type \\ One hot to policy \\ One hot to renew offercustomer_df \\ One hot to sales channel \\ One hot vehicle class \\ Ordinal vehicle size \\ \\ data[\"coverage\"] = data[\"coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2}) \\ given that column \"coverage\" in the dataframe \"data\" has three categories: \\ \"basic\", \"extended\", and \"premium\" and values are to be represented in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoder\n",
    "encoder = OneHotEncoder(handle_unknown='error', drop='first').fit(data_copy[['state', 'marital_status','policy_type','policy','renew_offer_type', 'sales_channel','vehicle_class']])\n",
    "encoded = encoder.transform(data_copy[['state', 'marital_status','policy_type','policy','renew_offer_type', 'sales_channel','vehicle_class']]).toarray()\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cat = pd.DataFrame(encoded)\n",
    "encoded_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeffa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cat.columns = encoder.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c357fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd492e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDINAL ENCODING\n",
    "# Ordinal to coverage \\ Ordinal to employmentstatus \\ Ordinal to location code \\ Ordinal vehicle size\n",
    "ordinal = data_copy[['coverage','employmentstatus','location_code','vehicle_size']]\n",
    "ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd870f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. encode the coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f477607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see unique values\n",
    "ordinal.coverage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intuitively we want to rank like this:\n",
    "# Define a dictionary for encoding variable\n",
    "cov_dict = {'Basic':0,\n",
    "            'Extended':1,\n",
    "            'Premium':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33722b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mapped values in a new column\n",
    "ordinal['coverage'] = ordinal['coverage'].map(cov_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ef41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data\n",
    "ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encode the employmentstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll put Medical leave, Disabled and Retired in a new category called 'other'.\n",
    "# we could also put these in unemployed but I'd say from a monetary perspective they wouldn't get the same revenues,\n",
    "# for ex, a retired person has (ideally) more revenue and proprietary goods than an unemployed person\n",
    "count_emp = pd.DataFrame(ordinal['employmentstatus'].value_counts())\n",
    "count_emp = count_emp.reset_index()\n",
    "count_emp.columns = ['status', 'counts']\n",
    "other_df = count_emp[count_emp['counts']<500]\n",
    "other_df = list(other_df['status'])\n",
    "other_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the three categories \"employed, unemployed, other\"\n",
    "def clean_employement_status(x):\n",
    "    if x in other_df:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "ordinal['employmentstatus'] = list(map(clean_employement_status, ordinal['employmentstatus']))\n",
    "ordinal.employmentstatus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now how would we order it, to better serve our analysis and in a way that is relevant to our target?\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=ordinal['employmentstatus'],y=customer_df['total_claim_amount'], color='turquoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7048383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'least' employed have the most claim amount - I will order it from 0 (least employment) to 2 (most employment)\n",
    "# Define a dictionary for encoding variable\n",
    "emp_dict = {'Unemployed':0,\n",
    "            'Other':1,\n",
    "            'Employed':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mapped values in a new column\n",
    "ordinal['employmentstatus'] = ordinal['employmentstatus'].map(emp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode the location_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see the more cars, the higher the total_claim_amount\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=ordinal['location_code'],y=customer_df['total_claim_amount'], color='turquoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for encoding variable\n",
    "loc_dict = {'Rural':0,\n",
    "            'Urban':1,\n",
    "            'Suburban':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b48e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mapped values in a new column\n",
    "ordinal['location_code'] = ordinal['location_code'].map(loc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe25fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Encode the vehicle_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for encoding variable\n",
    "car_dict = {'Small':0,\n",
    "            'Medsize':1,\n",
    "            'Large':2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mapped values in a new column\n",
    "ordinal['vehicle_size'] = ordinal['vehicle_size'].map(car_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b128a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinate all encoded categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58106678",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal.reset_index(drop=True, inplace=True)\n",
    "encoded_cat.reset_index(drop=True, inplace=True)\n",
    "final_cat = pd.concat([ordinal, encoded_cat], axis=1)\n",
    "final_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all data (final_cat and numerical_df) together \n",
    "data = pd.merge(numerical_df, final_cat, how='left', left_index=True, right_index=True)\n",
    "data = data.drop('total_claim_amount', axis=1)\n",
    "target = pd.DataFrame(customer_df['total_claim_amount'])\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "target.reset_index(drop=True, inplace=True)\n",
    "data = pd.merge(data, target, how='left', left_index=True, right_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd2b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NaNs\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955dd99",
   "metadata": {},
   "source": [
    "# Lab | Comparing regression models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c44cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this final lab, we will model our data. Import sklearn train_test_split and separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84384931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate target\n",
    "y = data['total_claim_amount']\n",
    "X = data.drop('total_claim_amount', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff2221",
   "metadata": {},
   "source": [
    "## Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be643f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_1(y, X, test_size=0.3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train )\n",
    "    predictions = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    RMSE = mean_squared_error(y_test, predictions, squared=False)\n",
    "    MSE = mean_squared_error(y_test, predictions)\n",
    "    MAE = mean_absolute_error(y_test, predictions)\n",
    "    print(\"R2 =\", round(r2,2)), print(\"RMSE =\", round(RMSE,2)), print(\"MSE =\", round(MSE,2)), print(\"MAE =\", round(MAE,2))\n",
    "    return predictions, y_test, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1, y_test1, r2_1 = modeling_1(y, X, test_size=0.24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4c009",
   "metadata": {},
   "source": [
    "3. Great! Now define a function that takes a list of models and train (and tests) them so we can try a lot of them without repeating code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(y, X, models=[], test_size=0.3):\n",
    "    for model in models:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "        model.fit(X_train, y_train )\n",
    "        predictions = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        r2_adj = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "        RMSE = mean_squared_error(y_test, predictions, squared=False)\n",
    "        MSE = mean_squared_error(y_test, predictions)\n",
    "        MAE = mean_absolute_error(y_test, predictions)\n",
    "        print(model, 'metrics are: '), print(\"R2 =\", round(r2,2)), print(\"R2 adjusted =\", round(r2_adj,2)), print(\"RMSE =\", round(RMSE,2)), print(\"MSE =\", round(MSE,2)), print(\"MAE =\", round(MAE,2))\n",
    "    return predictions, y_test, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to check LinearRegressor and KNeighborsRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d51e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_test, r2 = modeling(y, X, models=[LinearRegression(), KNeighborsRegressor(n_neighbors=10)], test_size=0.24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c7480",
   "metadata": {},
   "source": [
    "4. You can check also the MLPRegressor for this task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_test, r2 = modeling(y, X, models=[LinearRegression(), KNeighborsRegressor(n_neighbors=10), MLPRegressor(max_iter=100)], test_size=0.24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff460308",
   "metadata": {},
   "source": [
    "5. Check and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee216e9",
   "metadata": {},
   "source": [
    "Let's check how the predictions compare to the results. \\ We could improve the function to run different k values and return the best predictions. \\ Same with the MLP regressor and the max_iter values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493402fc",
   "metadata": {},
   "source": [
    "## Finding the best K value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56470b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(2,15): \n",
    "    model = KNeighborsRegressor(n_neighbors=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(2,15), scores, color = 'blue', linestyle='dashed',\n",
    "marker='o', markerfacecolor='red', markersize=10)\n",
    "plt.title('R2 vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb413b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> the best k-value is 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_predictions, k_y_test, k_r2 = modeling(y, X, models=[KNeighborsRegressor(n_neighbors=10)], test_size=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ededf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_predictions, LR_y_test, LR_r2 = modeling(y, X, models=[LinearRegression()],test_size=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_predictions, y_test, MLP_r2 = modeling(y, X, models=[MLPRegressor(max_iter=250)],test_size=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27234e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_results = diff_df(y_test, k_predictions)\n",
    "k_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_results = diff_df(y_test, LR_predictions)\n",
    "LR_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_results = diff_df(y_test, MLP_predictions)\n",
    "MLP_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9095b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def we_like_to_see(results):\n",
    "    beautiful_graph = sns.regplot(results['true'], results['pred'])\n",
    "    return beautiful_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aff35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_beautiful_graph = we_like_to_see(k_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_beautiful_graph = we_like_to_see(LR_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f025090",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_beautiful_graph = we_like_to_see(LR_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most accurate results are obtained with the MLP regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3523d3",
   "metadata": {},
   "source": [
    "# The models could possibly be better at predicting the target, we can try revisiting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040424fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(numerical_df.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.heatmap(numerical_df.corr(), mask=mask, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(continuous.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax = sns.heatmap(continuous.corr(), mask=mask, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(discrete_df.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax = sns.heatmap(discrete_df.corr(), mask=mask, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d389fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(ordinal.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax = sns.heatmap(ordinal.corr(), mask=mask, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8881959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very little correlation between the discrete variables and the target, so let's run the model without those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_discrete = data.drop(columns=discrete_df.columns, axis=1)\n",
    "no_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffff6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dis_y = no_discrete['total_claim_amount']\n",
    "no_dis_X = no_discrete.drop('total_claim_amount', axis=1)\n",
    "no_dis_pred, no_dis_y_test, no_dis_r2 = modeling(no_dis_y, no_dis_X, models=[LinearRegression(), KNeighborsRegressor(n_neighbors=6), MLPRegressor(max_iter=250)], test_size=0.24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da3753",
   "metadata": {},
   "source": [
    "Differences:\n",
    "The KNN model seems to perform better once we remove the variables that are not statistically significant. We can recalculate the better k values and the difference with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dis_X_train, no_dis_X_test, no_dis_y_train, no_dis_y_test = train_test_split(no_dis_X, no_dis_y, test_size=0.24, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(2,15): \n",
    "    model = KNeighborsRegressor(n_neighbors=i)\n",
    "    model.fit(no_dis_X_train, no_dis_y_train)\n",
    "    scores.append(model.score(no_dis_X_test, no_dis_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(2,15), scores, color = 'blue', linestyle='dashed',\n",
    "marker='o', markerfacecolor='red', markersize=10)\n",
    "plt.title('R2 vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ad2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> the best k-value is 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614097c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2_predictions, k2_y_test, k2_r2 = modeling(no_dis_y, no_dis_X, models=[KNeighborsRegressor(n_neighbors=6)], test_size=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5fca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2_results = diff_df(no_dis_y_test, k2_predictions)\n",
    "k2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2_beautiful_graph = we_like_to_see(k2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67385ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_beautiful_graph = we_like_to_see(LR_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d3f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_beautiful_graph = we_like_to_see(MLP_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d52bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAZIT: Even though the KNN performs better now, it's still not as accurate as the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81e61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbf0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee504f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
